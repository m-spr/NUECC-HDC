{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.system('pwd')\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sympy import symbols, simplify_logic, Or\n",
    "from sympy.logic.boolalg import And, Or, Not, simplify_logic, SOPform\n",
    "from itertools import product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': ['0_1.mif', '2_1.mif', '1_1.mif', '5_1.mif', '9_1.mif', '4_1.mif', '3_1.mif', '8_1.mif', '7_1.mif', '6_1.mif'], '0': ['8_0.mif', '2_0.mif', '1_0.mif', '3_0.mif', '7_0.mif', '5_0.mif', '9_0.mif', '6_0.mif', '0_0.mif', '4_0.mif']}\n"
     ]
    }
   ],
   "source": [
    "#merge the generated mif files from the platform\n",
    "#directory to the generated memory\n",
    "#\n",
    "def merge_mif_files(directory):\n",
    "    # Dictionary to store file groups based on second index\n",
    "    file_groups = defaultdict(list)\n",
    "\n",
    "    # Regular expression to extract {index}_{subindex}.mif pattern\n",
    "    pattern = re.compile(r\"(\\d+)_(\\d+)\\.mif\")\n",
    "\n",
    "    # Get all .mif files and categorize them based on their second index\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mif\"):\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                first_index, second_index = match.groups()\n",
    "                file_groups[second_index].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHVs_1.mif', 'CHVs_0.mif']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the generated mif files from the platform\n",
    "def merge_mif_files(directory):\n",
    "    # Dictionary to store file groups based on second index\n",
    "    file_groups = defaultdict(list)\n",
    "\n",
    "    # Regular expression to extract {index}_{subindex}.mif pattern\n",
    "    pattern = re.compile(r\"(\\d+)_(\\d+)\\.mif\")\n",
    "\n",
    "    # Get all .mif files and categorize them based on their second index\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mif\"):\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                first_index, second_index = match.groups()\n",
    "                file_groups[second_index].append(filename)\n",
    "\n",
    "    # Sort file groups by second index\n",
    "    for second_index, files in file_groups.items():\n",
    "        files.sort(key=lambda x: int(x.split(\"_\")[0]))  # Sort by first index\n",
    "\n",
    "        # Define output file\n",
    "        output_file = os.path.join(directory, f\"CHV_{second_index}.mif\")\n",
    "\n",
    "        # Merge files\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(directory, file)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                    content = infile.read().strip()  # Read and strip spaces/newlines\n",
    "                    outfile.write(content + \"\\n\")  # Write content as a single line\n",
    "\n",
    "\n",
    "\n",
    "# make memory files\n",
    "def groupMifFiles(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".mif\")]\n",
    "\n",
    "    grouped_files = {}\n",
    "    for file in files:\n",
    "        class_index, index = file.replace(\".mif\", \"\").split(\"_\")\n",
    "        grouped_files.setdefault(index, []).append(file)\n",
    "\n",
    "    # print (grouped_files)\n",
    "\n",
    "    for index, file_list in grouped_files.items():\n",
    "        output_file = os.path.join(directory, f\"CHVs_{index}.mif\")\n",
    "        with open(output_file, \"w\") as outfile:\n",
    "            for filename in sorted(file_list, key=lambda x: int(x.split(\"_\")[0])):\n",
    "                with open(os.path.join(directory, filename), \"r\") as infile:\n",
    "                    outfile.write(infile.read().strip() + \"\\n\")\n",
    "                    \n",
    "def read_mif_file(file_path):\n",
    "    bitvectors = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            lines = line.strip()\n",
    "            if lines:  # Skip empty lines\n",
    "                bitvectors.append(lines)\n",
    "    return bitvectors\n",
    "\n",
    "def write_mif_file(file_path, j , bitvector):\n",
    "    with open(file_path+\"_\"+str(j)+\".mif\", 'w') as file:\n",
    "        file.write(f\"{''.join(bitvector)}\")\n",
    "\n",
    "\n",
    "def generate_flag_memory_file (bitvectors):\n",
    "    # Transpose bitvectors to analyze each bit position\n",
    "    num_bitstreams = len(bitvectors)        # Number of bitstreams (outermost list)\n",
    "    num_rows = len(bitvectors[0])          # Number of rows in each bitstream\n",
    "    num_cols = len(bitvectors[0][0])       # Number of columns in each row\n",
    "    \n",
    "    result = []\n",
    "    # transposed_bits = zip(*bitvectors)\n",
    "    # print(transposed_bits)\n",
    "    for row in range(num_rows):\n",
    "        flag_row = []\n",
    "        for col in range(num_cols):\n",
    "            # Collect elements from all bitstreams at position [row][col]\n",
    "            bits = [bitvectors[stream][row][col] for stream in range(num_bitstreams)]\n",
    "            # Check if all elements are the same\n",
    "            flag_row.append('1' if len(set(bits)) == 1 else '0')\n",
    "        # Append the flag row to the result\n",
    "        result.append(''.join(flag_row)) \n",
    "        \n",
    "    # flag_vector = ['0' if len(set(bits)) == 1 else '1' for bits in transposed_bits]\n",
    "    return result\n",
    "\n",
    "def generate_parity_memory_file(bitvectors, flag_vector):\n",
    "    parity_vector = []\n",
    "    result = []\n",
    "    for i in range(len(flag_vector)):\n",
    "        if flag_vector[i] == '1':\n",
    "                column = [bv[i] for bv in bitvectors]\n",
    "                parity = column.count('1') % 2\n",
    "                parity_vector.append(str(parity))\n",
    "        # print(\"parity is : \", parity_vector)\n",
    "    result.append(''.join(parity_vector))\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def Sizing_the_same(file_name, directory):\n",
    "    file_data = []\n",
    "    for filename in os.listdir():\n",
    "        if filename.startswith(file_name):\n",
    "            with open(filename, 'r') as file:\n",
    "                content = file.read().strip()\n",
    "                file_data.append((filename, content))\n",
    "    # print(file_data)\n",
    "    # Find the maximum length of the file contents\n",
    "    max_length = max(len(content) for _, content in file_data)\n",
    "\n",
    "    # Pad the contents of shorter files with leading zeros and save the changes\n",
    "    for filename, content in file_data:\n",
    "        if len(content) < max_length:\n",
    "            padding_needed = max_length - len(content)\n",
    "            padded_content = '0' * padding_needed + content\n",
    "            with open(os.path.join(directory, filename), 'w') as file:\n",
    "                file.write(padded_content)\n",
    "        else:\n",
    "            with open(os.path.join(directory, filename), 'w') as file:\n",
    "                file.write(content)\n",
    "\n",
    "# to make efficent hardware for ECC\n",
    "# Function to read a MIF file and process its content\n",
    "def process_mif_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Grouping values by occurrences in the file\n",
    "    value_groups = defaultdict(list)\n",
    "    \n",
    "    for index, line in enumerate(lines):\n",
    "        value = line.strip()\n",
    "        value_groups[value].append(index)\n",
    "\n",
    "    # Convert to dictionary\n",
    "    grouped_data = dict(value_groups)\n",
    "\n",
    "    # Determine the highest index for binary conversion\n",
    "    max_index = max(max(indexes) for indexes in grouped_data.values())\n",
    "    binary_length = len(bin(max_index)[2:])  # Get binary length\n",
    "\n",
    "    # Convert line indexes to binary\n",
    "    for key in grouped_data:\n",
    "        grouped_data[key] = [format(index, f'0{binary_length}b') for index in grouped_data[key]]\n",
    "\n",
    "    return grouped_data, binary_length\n",
    "\n",
    "# Function to generate VHDL ROM-based LUT code\n",
    "def generate_vhdl_rom(file_name, grouped_data, binary_length):\n",
    "    vhdl_code = f\"\"\"\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "\n",
    "entity ROM_LUT_{file_name} is\n",
    "    Port (\n",
    "        address : in STD_LOGIC_VECTOR({binary_length-1} downto 0);\n",
    "        data_out : out STD_LOGIC_VECTOR(4 downto 0) -- 5-bit value\n",
    "    );\n",
    "end ROM_LUT_{file_name};\n",
    "\n",
    "architecture Behavioral of ROM_LUT_{file_name} is\n",
    "begin\n",
    "    process(address)\n",
    "    begin\n",
    "        case address is\n",
    "    \"\"\"\n",
    "    \n",
    "    for value, indexes in grouped_data.items():\n",
    "        for index in indexes:\n",
    "            vhdl_code += f'            when \"{index}\" => data_out <= \"{value}\";\\n'\n",
    "\n",
    "    vhdl_code += \"\"\"\n",
    "            when others => data_out <= \"00000\"; -- Default case\n",
    "        end case;\n",
    "    end process;\n",
    "end Behavioral;\n",
    "    \"\"\"\n",
    "    \n",
    "    return vhdl_code\n",
    "\n",
    "def generate_vhdl_sop(file_name, grouped_data, binary_length):\n",
    "    num_output_bits = len(next(iter(grouped_data.keys())))  # Determine output bit width\n",
    "    variables = [symbols(f'A{i}') for i in range(binary_length)]  # Define input variables\n",
    "    simplified_expressions = {}\n",
    "\n",
    "    # Generate simplified SOP for each output bit\n",
    "    for bit_pos in range(num_output_bits):\n",
    "        boolean_expressions_bit = []\n",
    "        \n",
    "        for value, binary_indexes in grouped_data.items():\n",
    "            bit_value = int(value[bit_pos])\n",
    "            if bit_value == 1:\n",
    "                for binary_index in binary_indexes:\n",
    "                    terms = [variables[i] if bit == '1' else Not(variables[i]) for i, bit in enumerate(binary_index)]\n",
    "                    boolean_expressions_bit.append(And(*terms))  # Use AND for product terms\n",
    "\n",
    "        # Simplify SOP expression\n",
    "        if boolean_expressions_bit:\n",
    "            combined_expression = Or(*boolean_expressions_bit)  # Use OR for sum of products\n",
    "            simplified_expressions[f\"V{bit_pos}\"] = simplify_logic(combined_expression, form='dnf')\n",
    "\n",
    "    # Generate VHDL code for SOP logic\n",
    "    vhdl_code = f\"\"\"\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "\n",
    "entity SOP_LUT_{file_name} is\n",
    "    Port (\n",
    "        A : in STD_LOGIC_VECTOR({binary_length-1} downto 0);\n",
    "        V : out STD_LOGIC_VECTOR({num_output_bits-1} downto 0)\n",
    "    );\n",
    "end SOP_LUT_{file_name};\n",
    "\n",
    "architecture Behavioral of SOP_LUT_{file_name} is\n",
    "begin\n",
    "\"\"\"\n",
    "\n",
    "    # Convert simplified SOP expressions to VHDL syntax\n",
    "    for bit, expression in simplified_expressions.items():\n",
    "        vhdl_expr = str(expression).replace('~', 'not ').replace('&', ' and ').replace('|', ' or ')\n",
    "        vhdl_code += f\"    V({bit[-1]}) <= {vhdl_expr};\\n\"\n",
    "\n",
    "    vhdl_code += \"end Behavioral;\\n\"\n",
    "\n",
    "    return vhdl_code\n",
    "\n",
    "\n",
    "# Function to generate minimized SOP-based VHDL with don't cares\n",
    "def generate_vhdl_sop_with_dont_care(file_name, grouped_data, binary_length):\n",
    "    num_output_bits = len(next(iter(grouped_data.keys())))  # Determine output bit width\n",
    "    variables = [symbols(f'A{i}') for i in range(binary_length)]  # Define input variables\n",
    "    simplified_expressions = {}\n",
    "\n",
    "    # Generate all possible binary indexes (0 to 2^binary_length - 1)\n",
    "    all_indexes = {format(i, f'0{binary_length}b') for i in range(2**binary_length)}\n",
    "    \n",
    "    # Determine used indexes and don't care indexes\n",
    "    used_indexes = {index for indexes in grouped_data.values() for index in indexes}\n",
    "    dont_care_indexes = all_indexes - used_indexes  # All missing indexes are don't cares\n",
    "\n",
    "    # Generate minimized SOP for each output bit\n",
    "    for bit_pos in range(num_output_bits):\n",
    "        minterms = []\n",
    "        dont_cares = []\n",
    "        \n",
    "        for value, binary_indexes in grouped_data.items():\n",
    "            bit_value = int(value[bit_pos])\n",
    "            if bit_value == 1:  # Add minterms for '1' values\n",
    "                for binary_index in binary_indexes:\n",
    "                    minterms.append(tuple(int(bit) for bit in binary_index))\n",
    "\n",
    "        # Convert don't care conditions to tuple format for SOPform minimization\n",
    "        for binary_index in dont_care_indexes:\n",
    "            dont_cares.append(tuple(int(bit) for bit in binary_index))\n",
    "\n",
    "        # Simplify SOP expression using ESPRESSO (handles don't cares correctly)\n",
    "        if minterms:\n",
    "            simplified_expr = SOPform(variables, minterms, dont_cares)\n",
    "            simplified_expressions[f\"V{bit_pos}\"] = simplified_expr\n",
    "\n",
    "    # Generate VHDL code for SOP logic\n",
    "    vhdl_code = f\"\"\"\n",
    "library IEEE;\n",
    "use IEEE.STD_LOGIC_1164.ALL;\n",
    "\n",
    "entity SOP_LUT_{file_name} is\n",
    "    Port (\n",
    "        A : in STD_LOGIC_VECTOR({binary_length-1} downto 0);\n",
    "        V : out STD_LOGIC_VECTOR({num_output_bits-1} downto 0)\n",
    "    );\n",
    "end SOP_LUT_{file_name};\n",
    "\n",
    "architecture Behavioral of SOP_LUT_{file_name} is\n",
    "begin\n",
    "\"\"\"\n",
    "\n",
    "    # Convert simplified SOP expressions to VHDL syntax\n",
    "    for bit, expression in simplified_expressions.items():\n",
    "        vhdl_expr = str(expression).replace('~', 'not ').replace('&', ' and ').replace('|', ' or ')\n",
    "        vhdl_code += f\"    V({bit[-1]}) <= {vhdl_expr};\\n\"\n",
    "\n",
    "    vhdl_code += \"end Behavioral;\\n\"\n",
    "\n",
    "    return vhdl_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # File paths\n",
    "    directory = './hardware/RCEHDC/mnist_example/mem/normal/'\n",
    "    output_dir = './hardware/RCEHDC/mnist_example/mem/normal/'\n",
    "    groupMemFiles = [f for f in os.listdir(directory) if f.startswith(\"CHV\") and f.endswith(\".mif\")]\n",
    "    groupECCMem = [f for f in os.listdir(directory) if f.startswith(\"ECC_memory_file_\") and f.endswith(\".mif\")]\n",
    "    # Read the bitvectors from CHV_img.mif\n",
    "    print(groupECCMem)\n",
    "    groupMemFiles.reverse()\n",
    "    for i, eccMem in enumerate(groupECCMem):\n",
    "        grouped_data, binary_length = process_mif_file(directory+eccMem)\n",
    "        # print(grouped_data, binary_length) \n",
    "        file_name = str(i)\n",
    "        print(i , eccMem)\n",
    "        \n",
    "        vhdl_code = generate_vhdl_sop(file_name, grouped_data, binary_length)\n",
    "        vhdl_file_path = os.path.join(output_dir, f\"SOP_LUT_{file_name}.vhd\")\n",
    "        with open(vhdl_file_path, \"w\") as vhdl_file:\n",
    "            vhdl_file.write(vhdl_code)\n",
    "        \n",
    "        vhdl_code = generate_vhdl_sop_with_dont_care(file_name, grouped_data, binary_length)\n",
    "        vhdl_file_path = os.path.join(output_dir, f\"SOP_LUT_simple_{file_name}.vhd\")\n",
    "        with open(vhdl_file_path, \"w\") as vhdl_file:\n",
    "            vhdl_file.write(vhdl_code)\n",
    "        \n",
    "        vhdl_code = generate_vhdl_rom(file_name, grouped_data, binary_length)\n",
    "        vhdl_file_path = os.path.join(output_dir, f\"ECC_mem_rom_{file_name}.vhd\")\n",
    "        with open(vhdl_file_path, \"w\") as vhdl_file:\n",
    "            vhdl_file.write(vhdl_code)\n",
    "        \n",
    "    for i, CHVs in enumerate(groupMemFiles):\n",
    "        input_file = directory+CHVs\n",
    "        # print(input_file, i)\n",
    "        bitvectors = read_mif_file(input_file)\n",
    "        # print(bitvectors)\n",
    "\n",
    "        flag_vector = generate_flag_memory_file(bitvectors) \n",
    "        write_mif_file(\"flag_memory\", i, flag_vector)\n",
    "        parity_vector = generate_parity_memory_file(bitvectors, flag_vector)\n",
    "        write_mif_file(\"parity_memory\", i, parity_vector)\n",
    "        \n",
    "        Sizing_the_same(\"parity_memory\", directory)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed! Created 2 output files.\n"
     ]
    }
   ],
   "source": [
    "merge_mif_files('./hardware/RCEHDC/mnist_example/mem/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000000000000000000000011000000111001111111111111010111110110011100000000000000111000000001110001100000001100000001000011001110000000000001110001001110111101100000011111100000001100101111000001011111111111111101111000011101000001110001111000111100000011111111100111111101001111100111000000111000000001111111100000111110001011100011000010000000000011100101110000011011111101111111001110010000000000101111101111000000001100111000001111111111010000010001111010000000100101100011001000011111111110000000011111001001000111100011000001101110001001000100001110100001101111110111111100110000001110111111000000111011000001111110000000111111111111111110111110110111111111111001000010011001001111001100001100111001100111011110000111111100011111100000000011000000000001000000010010000001111111111111111100111110110001111111100000111000001111001101110110000011111011111101110111111100010001000111011111100111101111110111101110000011110111111100001000000010011100011000000001111111000000000010001111111000111010100010111111111110011011', '0000000000000000000000000011000000100001111111111111110111110000001100000000000000111110000111111111100000011000000001100000000000001100000011100001011000001111110000000100111111101100101100000001011111111111111111111000011100000001110111111000011101000011111111110111111101001011111111000000111000000001111111100000011110000111101011110000000000000111000001110000011011111101111111110010010000000000001100101110001100001111111100001111111111010000010001111000000000100111100011001111111111111011000000011111011001000111100011000101110110001001011100001111100111101111110111110000110000100010001011111110111011000000111001100000110001111111111010011110110111111111111111100000011001000000000111001100111001100111011110011000111100011111100000000011000000000010100111010010000001111111111111110110111110111111111111110000111111001111001111110110000011110011111111110101111110000000000000100110110111101111110111101110011111101100000000001010000010000001000000100001111111000000000010001111110000000011101100100001111110011000', '0000000000000000000000000011000000111001111111111111010111110000001100000000000000111100000111110001100000011100000001100000000000000000000001010001000110111111110000000000111111111100101100000001011111111111111101111000001100000001110001110000010011100011111111110111111101001011111111000000111000000001111111100000011110000111101011110000000000001111000111110000011001111101111111111100010000000000011100101100000000001101111100001111111111011000011000101000000000100110100011001101111111111010000001011111000001000111100011000101111110001001011000001111100111101111110111110000010000000010001111111110111111000000111110000000000001111111111110011110110111111111111111100010011001001111000100001100111001100111011110000100111100111111100000000011000000000011000100010010000001111111111111000111011110110011111111110000111100001111001111110111000011111000011111110111111100000000000011100111111111101111110111001110011111100000111110001000000010000001100000100001111111000001000010001111110110000000001100111111111110011011', '0000000000000000000000000011000000100001111111111111110111110000011100000000000000111110000011111111100011100100000001100000000000000000000001010001000000111001110000100111111110001100101100000001011111111111111101111000011100000001110001110000111100100011111111110111111101001011111111000000111000000001111111100000011100000011100011110000000000001111000111110000011011111101111111000100010000001000001111101100000000001110011100001111111111010000010001111010000000100111000111001111111111111010000111011111010001000111100011000001111110001001011100001111100111101111110111110000000000000010111011110000111011000000111100000000111111111111111111111110110111111111111111100010011000001111000010001100111001100111011110011100111100011111100000000011000000000011110110010010000001111111111111100110011110111111111111110000111001001111001101110110000011110011111111110111111100000000000000100111111111100011110111111110000011100000001110001000000011100001000000000001111111000001100010001111110111000100001011101110111110011011', '0000000000000000000000000011000000100001111111111111010111110000001100000000001110111000000111111111100000111100000001000000000000000000001101110011111000011101110000000111111000001100111111000001011111111111111001111000011101000001110000001000111100000011111111110111111101001011111111000000111000000001111111100000011100000111111011110010000000000011000001110000011011111101111111001110010000000000111111101100000000001110001000000111111111010000010000111001000000110111000011001111111111111011000111111111001001000111100011000101111110001001000000001111101111101111110111000010110000000010011111001110111011000000111110000000001111111111111111111110110111111111111111100010011001000011000100001100111001100111011110011000111100111111100000000011000000000011000100010010000001111111111111101111111110111011111111110000111000001111001111110110000011111011111111110111111100000000000000111111100111101111110111110110011011100000111110001100000111100001100000000001111111000010010010001111110000000000001000111101111100011000', '0000000000000000000000000011000000100001111111111111010111110110001100000000001000001000000001111111100000000100000000000000000000000000000011110011000000111001100000000111111110001100101100000001011111111111111101111000011100000001110001111000111100000011111111110111111101001011111111000000111000000001111111100000011110000111100011110010000000000011000001110000011011111101111111000000010000000000001111101100000000001110011100001111111111010000010001111010000000100111000011001101111111111011000000011111000001000111100011000001110110001001011100001111100111101111110111111100110000001110011011000000111011000000111110000100111111111111111111111110110111111111111111100010011001000111000111001100111001100111011110011000111100011111100000000011000000000011000100010010000001111111111111111110111110111111111111100000111000001111001101110110000011110011111111110111111100000000000000111111100111100011110111101110000011101100001100001000000011100001000000000001111111000010000010001111111110000001101100111101111100011011', '0000000000000000000000000011000000111001111111111111010111110000000000000000001100111111110001110011100000000000000000000000011111000000000101110011011110111001110000000111111111111100111111000001011111111111111101111000011101000001110000011000011100000011111111110111111101001011111111000000111000000001111111100000011110000111111011110000000000010011000001110000011011111101111111111110010000010000000111101111000000001100011000000111111110010000011001100010000000100111000011000001111111111011000000011111001001000111100011000101101110001001000000001111100111101111110111111001110000111010111111111110111011000000111110000100111101111111111001100010110111111111111111100010011001000111000100001000111001100111011110011000111100111111100000000011000000000011000100110010000001111111111111111110011110110111111111100000111000001111001101110110000011110011111111110111111100000000000000111111000111101111110110011110010011100000111110001100000010100001011000100001111111000000000010001111110000000000000011111101111000011011', '0000000000000000000000000011000000100001111111111111010111110000001100000000010000000000000111111111100000000000000001100000000000010000000001100001100000011111110000001111110000001100011111000001011111111111110001111000011101000001110001111000111100000011111111110111111101001011111111000000111000000001111111100000111110000111111011110010000000000011011001110000011011111101111111001110010000000000001111101100001100001110001100001111111111010000010001111000000000111101000011001111111111111010000001011111001001000111100011000101111110001001000000001111101111101111110111100110110000000010011111001110111011000000111110000000111111111111111110111110110111111111111111111110011001000111000100001100111001100111011110000000111100111100100000000011000000000011010110010010000001111111111111000111111110111111111111110000111110001111001101110110000011111011111111110011110000000000000000111110100111101111110111111110011011101111111100001000000011100001000000000001111111000010010010001111110000000001001101111101111100011000', '0000000000000000000000000011000000100001111111111111010111110000011100000000010000110100000001110111100000011100000001100000000000100100000001110001011000111001110000000111111110001100101100000001011111111111111101111000011100000001110001010000111111100011111111110111111101001011111111000000111000000001111111100000111100000111100011110010000000001111000111110000011011111101111111001100010000010000000111101100001100001110111100001111111111010000010001111000000000100101100011000000111111111011000111111111011001000111100011000101101110001001011100001111100111101111110111111000110000000010111011110000111011000001111100000100111111111111111011111110110111111111111111100010011001001111000110001100111001100111011110000000111100011111100000000011000000000011010000010010000001111111111111111110111110110011111111100000111111001111001101110110000011110001011111110111111100000000000000111110100111100011110111001110000011101100111110001000000011100001000000000001111111000000000010001111111000000100101100111100111110011010', '0000000000000000000000000011000000100001111111111111010111110000001100000000000010000100000111111111100000101100000001100000000000000000000001110011010000011101110000000111111100001100101111000001011111111111111001111000011101000101110000001000111100000011111111110111111101001011111111000000111000000001111111100000111100000111111011010010000000000011001001110000011011111101111111001110010000010000011111101100001100001110001000000111111111010000010000111001000000110101000011001111111111111111000111111111001001000111100011000101111110001001000000001111100111101111110111000000110000000010011111000110111011000000111110000000111111111111111110111010110111111111111111100010011001000111000100001100111001100111011110011000111100111111100000000011000000000011000100010010000001111111111111000110111110111111111111110000111100001111001111110110000011111011111111110111111100000000000000111110100111101111110111111110010011101111111100001100000111100001000000000001111111000010000010001111111000000000001000111101111100011000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "input_file = 'CHV_img.mif'  # Replace with the path to your file\n",
    "segment_number = 2  # Specify the segment number\n",
    "generate_flag_memory_file(bitvectors, segment_size, output_file_base)\n",
    "\n",
    "print(rearranged_bitstreams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def rearrange_bitstream(file_path, segment_number):\n",
    "#     \"\"\"\n",
    "#     Rearranges bitstreams from a .mif file based on a given segment number.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path to the input .mif file.\n",
    "#         segment_number (int): Number used to segment the bitstream.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of rearranged bitstreams.\n",
    "#     \"\"\"\n",
    "#     rearranged_bitstreams = []\n",
    "\n",
    "#     # Read the .mif file and extract the bitstreams\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "\n",
    "#     # Process each line as a bitstream\n",
    "#     for line in lines:\n",
    "#         bitstream = line.strip()  # Remove whitespace or newline\n",
    "#         if not bitstream:\n",
    "#             continue\n",
    "#         bit_length = len(bitstream)\n",
    "\n",
    "#         # Ensure the bitstream length is compatible with the segment_number\n",
    "#         if bit_length % segment_number != 0:\n",
    "#             print(f\"Warning: Bitstream length {bit_length} is not divisible by {segment_number}\")\n",
    "#             continue\n",
    "\n",
    "#         segment_size = bit_length // segment_number\n",
    "#         rearranged = []\n",
    "\n",
    "#         # Perform the rearrangement\n",
    "#         for i in range(segment_size):\n",
    "#             for j in range(segment_number):\n",
    "#                 rearranged.append(bitstream[i + j * segment_size])\n",
    "\n",
    "#         rearranged_bitstreams.append(''.join(rearranged))\n",
    "\n",
    "#     return rearranged_bitstreams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
